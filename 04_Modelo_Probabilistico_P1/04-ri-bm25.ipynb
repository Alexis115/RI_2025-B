{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3025,"sourceType":"datasetVersion","datasetId":1740}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T16:41:54.911515Z","iopub.execute_input":"2025-11-12T16:41:54.911877Z","iopub.status.idle":"2025-11-12T16:42:40.960720Z","shell.execute_reply.started":"2025-11-12T16:41:54.911850Z","shell.execute_reply":"2025-11-12T16:42:40.959644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 4: Modelo Probabilístico\nObjetivo de la práctica\n* Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n* Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n* Comparar la recuperación con BM25 frente a TF-IDF.\n* Analizar visualmente las diferencias entre los modelos.\n* Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes.","metadata":{}},{"cell_type":"markdown","source":"## Parte 0: Carga del Corpus","metadata":{}},{"cell_type":"code","source":"import os\n\nbase_path = \"/kaggle/input/20-newsgroups\"\nfor folder in os.listdir(base_path):\n    print(folder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T16:46:31.657548Z","iopub.execute_input":"2025-11-12T16:46:31.658393Z","iopub.status.idle":"2025-11-12T16:46:31.670965Z","shell.execute_reply.started":"2025-11-12T16:46:31.658365Z","shell.execute_reply":"2025-11-12T16:46:31.669868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Ruta a tu carpeta con los 20 archivos .txt\ndata_dir = \"/kaggle/input/20-newsgroups\"\n\n# Crear una lista para almacenar todo el texto (el corpus)\ncorpus = []\n\n# Recorrer los 20 archivos .txt\nfor fname in sorted(os.listdir(data_dir)):\n    if fname.endswith(\".txt\"):\n        path = os.path.join(data_dir, fname)\n        with open(path, encoding=\"utf-8\", errors=\"ignore\") as f:\n            text = f.read().strip()\n            corpus.append(text)\n\nprint(f\"Total documentos cargados: {len(corpus)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:05:11.475647Z","iopub.execute_input":"2025-11-12T17:05:11.475999Z","iopub.status.idle":"2025-11-12T17:05:11.635971Z","shell.execute_reply.started":"2025-11-12T17:05:11.475974Z","shell.execute_reply":"2025-11-12T17:05:11.634909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corpus","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:05:19.361384Z","iopub.execute_input":"2025-11-12T17:05:19.361711Z","iopub.status.idle":"2025-11-12T17:05:21.363759Z","shell.execute_reply.started":"2025-11-12T17:05:19.361687Z","shell.execute_reply":"2025-11-12T17:05:21.362160Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\nActividad\n* Utiliza el corpus cargado.\n* Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n* Calcula TF-IDF utilizando sklearn.\n* Visualiza los valores en un DataFrame para analizar las diferencias entre los términos.","metadata":{}},{"cell_type":"markdown","source":"### Limpiar el Corpus","metadata":{}},{"cell_type":"code","source":"import re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:20:49.403344Z","iopub.execute_input":"2025-11-12T17:20:49.403682Z","iopub.status.idle":"2025-11-12T17:20:49.410498Z","shell.execute_reply.started":"2025-11-12T17:20:49.403658Z","shell.execute_reply":"2025-11-12T17:20:49.409340Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:20:57.551453Z","iopub.execute_input":"2025-11-12T17:20:57.551758Z","iopub.status.idle":"2025-11-12T17:20:57.594647Z","shell.execute_reply.started":"2025-11-12T17:20:57.551723Z","shell.execute_reply":"2025-11-12T17:20:57.593375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_text(text):\n    # Minusculas\n    text = text.lower()\n    \n    # Quitar puntuación y números\n    text = re.sub(r'[^a-z\\s]', '', text)\n    \n    # Tokenizar\n    tokens = text.split()\n    \n    # Quitar stopwords y lematizar\n    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n    \n    # Unir tokens nuevamente en string\n    return \" \".join(tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:21:13.556684Z","iopub.execute_input":"2025-11-12T17:21:13.556979Z","iopub.status.idle":"2025-11-12T17:21:13.562928Z","shell.execute_reply.started":"2025-11-12T17:21:13.556960Z","shell.execute_reply":"2025-11-12T17:21:13.561888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessed_corpus = [preprocess_text(doc) for doc in corpus]\n\nprint(\"Documento original:\")\nprint(corpus[0][:300])\n\nprint(\"\\nDocumento preprocesado:\")\nprint(preprocessed_corpus[0][:300])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:21:28.915431Z","iopub.execute_input":"2025-11-12T17:21:28.915723Z","iopub.status.idle":"2025-11-12T17:22:01.001253Z","shell.execute_reply.started":"2025-11-12T17:21:28.915704Z","shell.execute_reply":"2025-11-12T17:22:01.000140Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Crear la matriz de terminos TF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# Inicializamos el vectorizador\nvectorizer = CountVectorizer(stop_words='english')  # eliminamos stopwords básicas\nX_tf = vectorizer.fit_transform(preprocessed_corpus)\n\n# X_tf es una matriz sparse (20 documentos x n_terms)\nprint(\"Matriz TF:\", X_tf.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:22:27.566358Z","iopub.execute_input":"2025-11-12T17:22:27.566664Z","iopub.status.idle":"2025-11-12T17:22:32.712849Z","shell.execute_reply.started":"2025-11-12T17:22:27.566645Z","shell.execute_reply":"2025-11-12T17:22:32.711675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Obtener la lista de terminos","metadata":{}},{"cell_type":"code","source":"terms = vectorizer.get_feature_names_out()\nprint(\"Número de términos:\", len(terms))\nprint(\"Primeros 10 términos:\", terms[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:22:41.501235Z","iopub.execute_input":"2025-11-12T17:22:41.501589Z","iopub.status.idle":"2025-11-12T17:22:41.685694Z","shell.execute_reply.started":"2025-11-12T17:22:41.501566Z","shell.execute_reply":"2025-11-12T17:22:41.684516Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Calcular la frecuencia de documentos DF","metadata":{}},{"cell_type":"code","source":"# Convertimos la matriz TF a booleana: 1 si la palabra aparece, 0 si no\nX_bool = (X_tf > 0).astype(int)\n\n# Sumamos a lo largo de las filas para obtener DF\ndf_counts = np.array(X_bool.sum(axis=0)).flatten()\n\n# Creamos un DataFrame para ver los resultados\nimport pandas as pd\ndf = pd.DataFrame({\"term\": terms, \"DF\": df_counts})\ndf = df.sort_values(by=\"DF\", ascending=False)\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:22:59.716634Z","iopub.execute_input":"2025-11-12T17:22:59.716982Z","iopub.status.idle":"2025-11-12T17:22:59.780109Z","shell.execute_reply.started":"2025-11-12T17:22:59.716957Z","shell.execute_reply":"2025-11-12T17:22:59.779162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualizar matriz TF-DF","metadata":{}},{"cell_type":"code","source":"# Convertir matriz sparse a DataFrame (solo si quieres inspeccionarla)\ntf_df = pd.DataFrame(X_tf.toarray(), columns=terms)\ntf_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:23:07.893666Z","iopub.execute_input":"2025-11-12T17:23:07.894185Z","iopub.status.idle":"2025-11-12T17:23:07.968966Z","shell.execute_reply.started":"2025-11-12T17:23:07.894161Z","shell.execute_reply":"2025-11-12T17:23:07.967792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Calcular matriz TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:23:15.169529Z","iopub.execute_input":"2025-11-12T17:23:15.169869Z","iopub.status.idle":"2025-11-12T17:23:15.174961Z","shell.execute_reply.started":"2025-11-12T17:23:15.169846Z","shell.execute_reply":"2025-11-12T17:23:15.173867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inicializamos TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english')  # opcional eliminar stopwords básicas\n\n# Ajustamos y transformamos el corpus\nX_tfidf = vectorizer.fit_transform(preprocessed_corpus)\n\n# Obtenemos la lista de términos\nterms = vectorizer.get_feature_names_out()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:23:36.481120Z","iopub.execute_input":"2025-11-12T17:23:36.481472Z","iopub.status.idle":"2025-11-12T17:23:42.263629Z","shell.execute_reply.started":"2025-11-12T17:23:36.481450Z","shell.execute_reply":"2025-11-12T17:23:42.262597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Número de documentos:\", X_tfidf.shape[0])\nprint(\"Número de términos:\", X_tfidf.shape[1])\nprint(\"Primeros 10 términos:\", terms[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:23:46.401626Z","iopub.execute_input":"2025-11-12T17:23:46.401962Z","iopub.status.idle":"2025-11-12T17:23:46.409009Z","shell.execute_reply.started":"2025-11-12T17:23:46.401937Z","shell.execute_reply":"2025-11-12T17:23:46.407410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=terms)\ntfidf_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:23:49.978859Z","iopub.execute_input":"2025-11-12T17:23:49.979656Z","iopub.status.idle":"2025-11-12T17:23:50.095903Z","shell.execute_reply.started":"2025-11-12T17:23:49.979623Z","shell.execute_reply":"2025-11-12T17:23:50.094934Z"}},"outputs":[],"execution_count":null}]}